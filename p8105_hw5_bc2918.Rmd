---
title: "Homework 5"
author: "Beibei Cao"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



```{r, error = TRUE}
city_prop_test = function(df) {
  
  n_unsovled ...
  n_total ... 
  
  prop.test(.....)
  
}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```


## Problem 2

Import and tidy the data from each file.
```{r, error = TRUE}
study_df = 
  # get file paths
  tibble(
    path = list.files("lda_data"),
  ) %>%
  # read each file 
  mutate(
    subject = str_remove(path, '.csv'),
    path = str_c("lda_data/", path),
    data = map(.x = path, ~read_csv(.x))
    ) %>% 
  # tidy data
  separate(subject, c("arm", "id")) %>% 
  mutate(
    arm = recode(arm, con = "control", exp = "experimental"),
    id = as.integer(id)
         ) %>%
  unnest(data) %>% 
  select(-path) %>% 
  # transform into long format 
  pivot_longer(
    week_1:week_8,
    names_prefix = "week_",
    names_to = "week",
    values_to = "observation"
  ) 

# preview
study_df
```

Make a spaghetti plot showing observations on each subject over time.

```{r fig.width = 10, fig.height = 6}
study_df %>% 
  # plot 
  ggplot(aes(x = week, y = observation, group = interaction(arm, id), color = arm)) +
  geom_point() + 
  geom_line(alpha = 0.7) +
  labs(
    title = "Observations over Time",
    x = "Week",
    y = "Observation",
    color = "Arm"
  )
```

It could be observed from the plot that the experimental group subjects generally have higher observations than the control group. There is also an increasing trend in the observations of the experimental group while the observations in the control group are stable across the 8 weeks.

# Problem 3

Build functions for the simulation.
```{r}
# function for a single trial of simulation with t-test
sim_norm_test = function(n = 30, mu = 0, sigma = 5) {
  x = rnorm(n, mean = mu, sd = sigma)
  temp = 
    t.test(x, mu = 0) %>% 
    broom::tidy() %>% 
    select(estimate, p.value) %>% 
    rename(mu_hat = estimate, p_value = p.value)
  return(temp)
}

# function for multiple trials
mutiple_test = function(trial = 5000, n = 30, mu = 0, sigma = 5){
  output = vector("list", trial)
  for (i in 1:trial) {
    output[[i]] = sim_norm_test(n, mu, sigma)
  }
  res = bind_rows(output)
  return(res)
}

# function to calculate rejection proportion 
rej_prop = function(res){
  prop = 
    res %>% 
    filter(p_value < 0.05) %>% 
    count()/nrow(res)
  
  return(prop$n)
}

# function to calculate average estimates
get_avg = function(res){
  avg = tibble(
    avg_estimate = mean(res$mu_hat),
    avg_rejected = mean(res$mu_hat[res$p_value < 0.05])
  )
  return(avg)
}
```

Simulate.
```{r}
set.seed(100)
res = 
  # set mu 0-6
  tibble(mu = seq(0,6)) %>% 
  mutate(
    # generate simulation data
    data = map(.x = mu, ~mutiple_test(mu = .x)),
    # calculated rejection proportion
    rej_prop = map(.x = data, ~rej_prop(.x)),
    # get average estimates for all samples and average estimates for samples with null rejected
    avg = map(.x = data, ~get_avg(.x))
    ) %>% 
  unnest(rej_prop, avg)
```

Check results. 
```{r}
res %>% unnest(data)
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of $\mu$ on the x axis.
```{r}
res %>% 
  ggplot(aes(x = mu, y = rej_prop)) +
  geom_point() +
  geom_smooth(size = 0.3, se = FALSE) +
  labs(
    title = "Null Rejection Proportion vs. True mean",
    x = "True Mean",
    y = "Proportion of Null Rejection"
    ) +
  scale_x_continuous(
    breaks = c(seq(0, 6)),
    labels = c(seq(0, 6))
  ) 
```

It could be observed from the plot that the effect size significantly effect the power. As the effect size deviating from 0, the proportion of rejecting null hypothesis gets higher and higher, which makes sense because the true mean now indeed is not 0 and the null should be rejected more and more likely as the difference gets larger.


Make a plot showing the average estimate of μ̂ (of total and of rejected samples) on the y axis and the true value of μ on the x axis. 
```{r}
res %>% 
  pivot_longer(
    avg_estimate:avg_rejected,
    names_to = "estimate_type",
    values_to = "estimate_value"
  ) %>%
  ggplot(aes(x = mu, y = estimate_value, color = estimate_type)) +
  geom_point(alpha = 0.7) +
  geom_smooth(size = 0.3, se = FALSE) +
  labs(
    title = "Estimated Mean vs. True mean",
    x = "True Mean",
    y = "Estimate Mean",
    color = "Estimate Type"
    ) +
  scale_x_continuous(
    breaks = c(seq(0, 6)),
    labels = c(seq(0, 6))
  ) 
```

The sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?
